<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Practial machine learning poject assignment by IgorHut</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Practial machine learning poject assignment</h1>
        <h2>Repo for project assignment for Coursera course Practical Machine Learning</h2>
        <a href="https://github.com/IgorHut/Practial_Machine_Learning_Poject_Assignment" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>
<a id="practical-machine-learning-by-coursera---project-assignment" class="anchor" href="#practical-machine-learning-by-coursera---project-assignment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Practical Machine Learning by Coursera - Project Assignment</h1>

<p>Igor Hut<br>
01 jun 2016   </p>

<h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  </p>

<p>In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information regarding the whole experiment is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>. </p>

<h2>
<a id="initial-preparation---loading-necessary-packages-and-basic-data-preparation" class="anchor" href="#initial-preparation---loading-necessary-packages-and-basic-data-preparation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Initial preparation - Loading necessary packages and basic data preparation</h2>

<div class="highlight highlight-source-r"><pre>library(<span class="pl-smi">caret</span>)
library(<span class="pl-smi">randomForest</span>)
library(<span class="pl-smi">rpart</span>)
library(<span class="pl-smi">rpart.plot</span>)</pre></div>

<h3>
<a id="downloading-the-data" class="anchor" href="#downloading-the-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Downloading the data</h3>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">trainDataUrl</span> <span class="pl-k">&lt;-</span><span class="pl-s"><span class="pl-pds">"</span>https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv<span class="pl-pds">"</span></span>
<span class="pl-smi">testDataUrl</span> <span class="pl-k">&lt;-</span> <span class="pl-s"><span class="pl-pds">"</span>https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv<span class="pl-pds">"</span></span>
<span class="pl-smi">trainData</span> <span class="pl-k">&lt;-</span> <span class="pl-s"><span class="pl-pds">"</span>./data/pml-training.csv<span class="pl-pds">"</span></span>
<span class="pl-smi">testData</span>  <span class="pl-k">&lt;-</span> <span class="pl-s"><span class="pl-pds">"</span>./data/pml-testing.csv<span class="pl-pds">"</span></span>
<span class="pl-k">if</span> (<span class="pl-k">!</span>file.exists(<span class="pl-s"><span class="pl-pds">"</span>./data<span class="pl-pds">"</span></span>)) {
  dir.create(<span class="pl-s"><span class="pl-pds">"</span>./data<span class="pl-pds">"</span></span>)
}
<span class="pl-k">if</span> (<span class="pl-k">!</span>file.exists(<span class="pl-smi">trainData</span>)) {
  download.file(<span class="pl-smi">trainDatUrl</span>, <span class="pl-v">destfile</span><span class="pl-k">=</span><span class="pl-smi">trainData</span>)
}
<span class="pl-k">if</span> (<span class="pl-k">!</span>file.exists(<span class="pl-smi">testData</span>)) {
  download.file(<span class="pl-smi">testDataUrl</span>, <span class="pl-v">destfile</span><span class="pl-k">=</span><span class="pl-smi">testData</span>)
}</pre></div>

<h3>
<a id="reading-in-and-checking-the-data" class="anchor" href="#reading-in-and-checking-the-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Reading in and checking the data</h3>

<p>After downloading the data from the data source, we can read the two csv files into two data frames.  </p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">trainDataRaw</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>./data/pml-training.csv<span class="pl-pds">"</span></span>)
<span class="pl-smi">testDataRaw</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>./data/pml-testing.csv<span class="pl-pds">"</span></span>)
dim(<span class="pl-smi">trainDataRaw</span>)</pre></div>

<pre><code>## [1] 19622   160
</code></pre>

<div class="highlight highlight-source-r"><pre>dim(<span class="pl-smi">testDataRaw</span>)</pre></div>

<pre><code>## [1]  20 160
</code></pre>

<p>As can be observed the training data set contains 19622 observations and 160 variables, while the testing data set contains 20 observations and 160 variables. The "classe" variable in the training set is the outcome to predict. </p>

<h3>
<a id="spliting-the-data-set" class="anchor" href="#spliting-the-data-set" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Spliting the data set</h3>

<p>We are going to split the training data set into a pure training data set (70%) and a validation data set (30%).The former will be used to perform cross validation in forthcoming steps.  </p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">33</span>)
<span class="pl-smi">inTrain</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-smi">trainDataRaw</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span><span class="pl-k">=</span><span class="pl-c1">0.7</span>, <span class="pl-v">list</span><span class="pl-k">=</span><span class="pl-c1">F</span>)
<span class="pl-smi">trainSet</span> <span class="pl-k">&lt;-</span><span class="pl-smi">trainDataRaw</span>[<span class="pl-smi">inTrain</span>, ]
<span class="pl-smi">testSet</span><span class="pl-k">&lt;-</span> <span class="pl-smi">trainDataRaw</span>[<span class="pl-k">-</span><span class="pl-smi">inTrain</span>, ]</pre></div>

<h3>
<a id="cleaning-the-data" class="anchor" href="#cleaning-the-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cleaning the data</h3>

<p>In this section we are going to reduce the number of features by removing variables with nearly zero variance, variables that are almost always NA, as well as variables that wouldn't play any meaningful role in the prediction task. </p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Removing vars with nearly zero variance</span>
<span class="pl-smi">nzv</span> <span class="pl-k">&lt;-</span> nearZeroVar(<span class="pl-smi">trainSet</span>)
<span class="pl-smi">trainSet</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainSet</span>[, <span class="pl-k">-</span><span class="pl-smi">nzv</span>]
<span class="pl-smi">testSet</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testSet</span>[, <span class="pl-k">-</span><span class="pl-smi">nzv</span>]

<span class="pl-c"># Removing vars that are almost always NA</span>
<span class="pl-smi">mostlyNA</span> <span class="pl-k">&lt;-</span> sapply(<span class="pl-smi">trainSet</span>, <span class="pl-k">function</span>(<span class="pl-smi">x</span>) mean(is.na(<span class="pl-smi">x</span>))) <span class="pl-k">&gt;</span> <span class="pl-c1">0.95</span>
<span class="pl-smi">trainSet</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainSet</span>[, <span class="pl-smi">mostlyNA</span><span class="pl-k">==</span><span class="pl-c1">F</span>]
<span class="pl-smi">testSet</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testSet</span>[, <span class="pl-smi">mostlyNA</span><span class="pl-k">==</span><span class="pl-c1">F</span>]

<span class="pl-c"># Removing variables that don't play any meaningful role in the prediction task (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp). These are the first five variables in the given data set.</span>

<span class="pl-smi">trainSet</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainSet</span>[, <span class="pl-k">-</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span>)]
<span class="pl-smi">testSet</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testSet</span>[, <span class="pl-k">-</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span>)]

dim(<span class="pl-smi">trainSet</span>)</pre></div>

<pre><code>## [1] 13737    54
</code></pre>

<div class="highlight highlight-source-r"><pre>dim(<span class="pl-smi">testSet</span>)</pre></div>

<pre><code>## [1] 5885   54
</code></pre>

<p>Now, the cleaned training data set contains 13737 observations and 54 variables, while the cross validation testing data set contains 5885 observations and 54 variables. The "classe" variable is still in the cleaned training set.</p>

<h2>
<a id="data-modeling" class="anchor" href="#data-modeling" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data modeling</h2>

<p>For the begining we will choose the <strong>Random Forest</strong> ML algorithm to fit a predictive model for activity recognition, and check how it behaves. This is our first choice since <strong>RF</strong> automatically selects important variables and is quite robust to correlated covariates &amp; outliers in general. We will use <strong>5-fold cross validation</strong> when applying the algorithm.  </p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Train function will be using 5-fold CV to select optimal tuning parameters</span>
<span class="pl-smi">trainFit</span> <span class="pl-k">&lt;-</span> trainControl(<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>, <span class="pl-v">number</span><span class="pl-k">=</span><span class="pl-c1">5</span>, <span class="pl-v">verboseIter</span><span class="pl-k">=</span><span class="pl-c1">F</span>)

<span class="pl-c"># Fitting the model on trainSet</span>
<span class="pl-smi">modelFit</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span> ., <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">trainSet</span>, <span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rf<span class="pl-pds">"</span></span>, <span class="pl-v">trControl</span><span class="pl-k">=</span><span class="pl-smi">trainFit</span>)

<span class="pl-c"># Print final model to check which tuning parameters it chose</span>
<span class="pl-smi">modelFit</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span></pre></div>

<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 27
## 
##         OOB estimate of  error rate: 0.28%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3905    1    0    0    0 0.0002560164
## B    3 2650    4    1    0 0.0030097818
## C    0    9 2386    1    0 0.0041736227
## D    0    0   11 2240    1 0.0053285968
## E    0    2    0    6 2517 0.0031683168
</code></pre>

<p>It can be seen that it decided to use 500 trees and try 27 variables at each split.</p>

<p>Further, we will estimate the performance of the model on the validation data set. </p>

<h3>
<a id="model-evaluation" class="anchor" href="#model-evaluation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model evaluation</h3>

<p>We are using the fitted model to predict the label (“classe”) in <code>testSet</code>. Confusion matrix enables us to compare the predicted versus the actual labels.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">preds</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit</span>, <span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testSet</span>)

<span class="pl-c"># Show the confusion matrix to get estimates of the accuracy and out-of-sample error</span>
confusionMatrix(<span class="pl-smi">testSet</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-smi">preds</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    0    0    0    1
##          B    2 1137    0    0    0
##          C    0    1 1025    0    0
##          D    0    0    9  955    0
##          E    0    0    0    0 1082
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9978          
##                  95% CI : (0.9962, 0.9988)
##     No Information Rate : 0.2846          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9972          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9988   0.9991   0.9913   1.0000   0.9991
## Specificity            0.9998   0.9996   0.9998   0.9982   1.0000
## Pos Pred Value         0.9994   0.9982   0.9990   0.9907   1.0000
## Neg Pred Value         0.9995   0.9998   0.9981   1.0000   0.9998
## Prevalence             0.2846   0.1934   0.1757   0.1623   0.1840
## Detection Rate         0.2843   0.1932   0.1742   0.1623   0.1839
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9993   0.9993   0.9955   0.9991   0.9995
</code></pre>

<p>So, the estimated accuracy of the model is 99.72% and the estimated out-of-sample error is 0.28%.
This is quite a promising result, thus we will use <strong>RF</strong> algorithm to perform prediction on the given test set of 20 cases.</p>

<h3>
<a id="decision-tree-visualization" class="anchor" href="#decision-tree-visualization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Decision tree visualization</h3>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">tree</span> <span class="pl-k">&lt;-</span> rpart(<span class="pl-smi">classe</span> <span class="pl-k">~</span> ., <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">trainSet</span>, <span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>class<span class="pl-pds">"</span></span>)
prp(<span class="pl-smi">tree</span>) <span class="pl-c"># this "fast" plot is better for visualisation of a complex tree than i.e.               fancyRpartPlot which would be crammed</span></pre></div>

<p><img src="Practical_Mach_Learing_Proj_Assign_files/figure-html/unnamed-chunk-8-1.png" alt=""></p>

<h2>
<a id="predicting-for-test-data-set" class="anchor" href="#predicting-for-test-data-set" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Predicting for test data set</h2>

<h3>
<a id="retraining-the-model" class="anchor" href="#retraining-the-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Retraining the model</h3>

<p>Before predicting on the test set, we will train the model, again, but this time on the full training set (<code>trainDataRaw</code>), rather than use a model obtained by fitting the reduced training set (<code>trainSet</code>). This should lead to more accurate predictions. Therefore we will repeat the whole data preprocessing procedure with <code>trainDataRaw</code> and <code>testDataRaw</code>.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Removing vars with nearly zero variance</span>
<span class="pl-smi">nzv</span> <span class="pl-k">&lt;-</span> nearZeroVar(<span class="pl-smi">trainDataRaw</span>)
<span class="pl-smi">trainFinal</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainDataRaw</span>[, <span class="pl-k">-</span><span class="pl-smi">nzv</span>]
<span class="pl-smi">testFinal</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testDataRaw</span>[, <span class="pl-k">-</span><span class="pl-smi">nzv</span>]

<span class="pl-c"># Removing vars that are almost always NA</span>
<span class="pl-smi">mostlyNA</span> <span class="pl-k">&lt;-</span> sapply(<span class="pl-smi">trainFinal</span>, <span class="pl-k">function</span>(<span class="pl-smi">x</span>) mean(is.na(<span class="pl-smi">x</span>))) <span class="pl-k">&gt;</span> <span class="pl-c1">0.95</span>
<span class="pl-smi">trainFinal</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainFinal</span>[, <span class="pl-smi">mostlyNA</span><span class="pl-k">==</span><span class="pl-c1">F</span>]
<span class="pl-smi">testFinal</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testFinal</span>[, <span class="pl-smi">mostlyNA</span><span class="pl-k">==</span><span class="pl-c1">F</span>]

<span class="pl-c"># Removing variables that don't play any meaningful role in the prediction task (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp). These are the first five variables in the given data set.</span>

<span class="pl-smi">trainFinal</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainFinal</span>[, <span class="pl-k">-</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span>)]
<span class="pl-smi">testFinal</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testFinal</span>[, <span class="pl-k">-</span>(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span>)]

<span class="pl-c"># Re-train the model with the full training set</span>

<span class="pl-smi">trainFit</span> <span class="pl-k">&lt;-</span> trainControl(<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>, <span class="pl-v">number</span><span class="pl-k">=</span><span class="pl-c1">5</span>, <span class="pl-v">verboseIter</span><span class="pl-k">=</span><span class="pl-c1">F</span>)
<span class="pl-smi">modelFinal</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span> ., <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">trainFinal</span>, <span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rf<span class="pl-pds">"</span></span>, <span class="pl-v">trControl</span><span class="pl-k">=</span><span class="pl-smi">trainFit</span>)</pre></div>

<h3>
<a id="aplying-the-final-model-for-prediction-on-the-test-data-set" class="anchor" href="#aplying-the-final-model-for-prediction-on-the-test-data-set" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Aplying the final model for prediction on the test data set</h3>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">preds</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFinal</span>, <span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testFinal</span>)
<span class="pl-smi">preds</span></pre></div>

<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/IgorHut/Practial_Machine_Learning_Poject_Assignment/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/IgorHut/Practial_Machine_Learning_Poject_Assignment/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/IgorHut/Practial_Machine_Learning_Poject_Assignment"></a> is maintained by <a href="https://github.com/IgorHut">IgorHut</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
